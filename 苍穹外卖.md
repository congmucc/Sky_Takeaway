

[TOC]

# 苍穹外卖学习记录

## 1 java方法

### 1.1 对于模块使用 && 结果类中的泛型的用法

#### 1.1.1 idea中一个模块如何使用另一个模块的类

> 在 [Maven](https://so.csdn.net/so/search?q=Maven&spm=1001.2101.3001.7020) 项目中，通过在 `pom.xml` 文件中添加依赖配置，就可以解决问题。
>
> 但是非 Maven 项目呢？IDEA 很好地提供了一个解决方案：**模块依赖**
>
> [在 IDEA 中，通过 module（模块） 依赖来解决一个模块中使用另一个模块中的类_一个模块依赖另外一个模块,另外一个模块怎么用这个模块的接口_知音12138的博客-CSDN博客](https://blog.csdn.net/qq_36722955/article/details/108929909)

#### 1.1.2idea中结果类中的泛型的用法

- 示例代码

```
    @GetMapping("/page")
    @ApiOperation("菜品分页查询")
    public Result<PageResult> page(DishPageQueryDTO dishPageQueryDTO) {
        log.info("菜品分页查询: {}", dishPageQueryDTO);
        PageResult pageResult = dishService.pageQuery(dishPageQueryDTO);
        return Result.success(pageResult);
    }
```

> 一般是在get请求中使用，对应的值就行

### 1.2 TODO使用

> TODO: 英语翻译为待办事项，备忘录。如果代码中有该标识，说明在标识处有功能代码待编写，待实现的功能在说明中会简略说明

```
// TODO 后期需要进行md5加密，然后再进行比对

这里可以在侧栏TODO中直接跳转
```



### 1.3 DTO层&&VO层的使用以及方法

#### 1.3.1 DTO层介绍

> 一般是一个实体类的一部分，用于其他功能的时候前端返回json数据进行封装，例如新增员工，有很多东西不需要，例如实体类中的修改时间，这些在新增员工的时候就不需要，但是穿过来的数据最好封装一下，就是DTO层。

#### 1.3.2 对于实体类和DTO数据转换

- BeanUtils.copyProperties()

```java
public void save(EmployeeDTO employeeDTO) {
    Employee employee = new Employee();
    // 对象的属性拷贝  第一个为源，第二个为目标，源拷贝到目标
    BeanUtils.copyProperties(employeeDTO, employee);
    employeeMapper.save(employeeDTO);
}
```

> DTO层在service层进入mapper层的时候最好转化为实体类，这是因为mapper层是面向数据库的。

#### 1.3.3 VO层

> 这个层是处理逻辑的，也类似与DTO层，举个例子，我需要返回两张表中的数据，或者一些其他数据，最常见的就是分页查询，如果含有子查询，就可以设置一个VO

### 1.4 接口线程（获取线程内使用者的id）p20

> **前端每发送一次请求都是一个单独的线程**，对于全局获取值，我们可以利用ThreadLocal来获取本线程的存储空间（一般会包装成一个工具类）

#### 1.4.1 ThreadLocal

**介绍：**

ThreadLocal 并不是一个Thread，而是Thread的局部变量。
ThreadLocal为每个线程提供单独一份存储空间，具有线程隔离的效果，只有在线程内才能获取到对应的值，线程外则不能访问。

**常用方法：**

- public void set(T value) 	设置当前线程的线程局部变量的值
- public T get() 		返回当前线程所对应的线程局部变量的值
- public void remove()        移除当前线程的线程局部变量

#### 1.4.2 封装类

```java
package com.sky.context;

public class BaseContext {

    public static ThreadLocal<Long> threadLocal = new ThreadLocal<>();

    public static void setCurrentId(Long id) {
        threadLocal.set(id);
    }

    public static Long getCurrentId() {
        return threadLocal.get();
    }

    public static void removeCurrentId() {
        threadLocal.remove();
    }

}
```

> 这里是从jwt解码中获取当前登录的id，如果想要更多，可以将封装类设置成map，然后进行使用



### 1.5 消息转换器（日期时间转换）p24

> 前后端保存可以使用正常格式，这个格式就是LocalDateTime
>
> 例如：后端显示这个2023-09-20T00:54:26.841607400
>
> 数据库中显示为：2022-02-15 15:51:20
>
> 前端显示为20230920005426
>
> 
>
> 前端不用修改

#### 1.5.1 在属性上加上注解，对日期进行格式化

- 实体类中

```java
//@JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss")
private LocalDateTime createTime;

//@JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss")
private LocalDateTime updateTime;
```

#### 1.5.2 在WebMvcConfiguration中重写SpringMVC的消息转换器，统一对日期类型进行格式处理

	/**
	 * 扩展Spring MVC框架的消息转化器
	 * @param converters
	 */
	protected void extendMessageConverters(List<HttpMessageConverter<?>> converters) {
	    log.info("扩展消息转换器...");
	    //创建一个消息转换器对象
	    MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter();
	    //需要为消息转换器设置一个对象转换器，对象转换器可以将Java对象序列化为json数据
	    converter.setObjectMapper(new JacksonObjectMapper());
	    //将自己的消息转化器加入容器中
	    converters.add(0,converter);
	}

时间格式定义，sky-common模块中

```java
package com.sky.json;

import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.module.SimpleModule;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;
import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.LocalTime;
import java.time.format.DateTimeFormatter;

import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;

/**
 * 对象映射器:基于jackson将Java对象转为json，或者将json转为Java对象
 * 将JSON解析为Java对象的过程称为 [从JSON反序列化Java对象]
 * 从Java对象生成JSON的过程称为 [序列化Java对象到JSON]
 */
public class JacksonObjectMapper extends ObjectMapper {

    public static final String DEFAULT_DATE_FORMAT = "yyyy-MM-dd";
    //public static final String DEFAULT_DATE_TIME_FORMAT = "yyyy-MM-dd HH:mm:ss";
    public static final String DEFAULT_DATE_TIME_FORMAT = "yyyy-MM-dd HH:mm";
    public static final String DEFAULT_TIME_FORMAT = "HH:mm:ss";

    public JacksonObjectMapper() {
        super();
        //收到未知属性时不报异常
        this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false);

        //反序列化时，属性不存在的兼容处理
        this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);

        SimpleModule simpleModule = new SimpleModule()
                .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT)))
                .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT)))
                .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT)))
                .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT)))
                .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT)))
                .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT)));

        //注册功能模块 例如，可以添加自定义序列化器和反序列化器
        this.registerModule(simpleModule);
    }
}

```



最后前端格式：2023-09-20 00:58



### 1.6 动态sql使用 建造者模式 && 链式调用 p26

场景：启用禁用员工账号，传过来的数据为status于id，一共有两个点

#### 1.6.1 动态sql进行复用代码

> 在这个含有两个传参的场景下，我们可以使用**动态sql**，在持久层中进行复用。
>
> 其中， 为了便于复用，我们可以直接在service中封装成一个实**体对象**，传给持久层。

#### 1.6.2 建造者模式，链式调用

> 需要使用在实体类中使用lombok @Builder注解

```
public void startOrStop(Integer status, Long id) {
    // 这个是对于单个更新，我们可以使用一个动态sql进行复用，然后传给持久层时需要传一个实体对象更利于复用

    // 普通情况下
    // Employee employee = new Employee();
    // employee.setStatus(status);
    // employee.setId(id);

    // 有builder的情况下,建造者模式，链式
    Employee employee = Employee.builder()
            .status(status)
            .id(id)
            .build();

    employeeMapper.update(employee);
}
```





### 1.7 切面式编程--公共字段填充 p32

> 公共字段填充的意思是： 如果在更新或者插入的时候需要输入更新人的id，时间，插入时的id，时间，创建时间，创建人
>
> 可以利用切面进行自动填充。

#### 1.7.1 自定义注解AutoFill， 用于标识需要进行公共字段自动填充的方法

- com.sky.annotation

```
package com.sky.annotation;

import com.sky.enumeration.OperationType;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

/**
 * 自定义注解，用于标识某个方法需要进行功能字段自动填充处理
 */

@Target(ElementType.METHOD) // 指定注解只能加在方法上面
@Retention(RetentionPolicy.RUNTIME) //表示该注解的信息将在运行时可见和可获取
public @interface AutoFill {
    // 指定数据库操作类型 UPDATE, INSERT
    OperationType value();
}

```

> annotation这个包是专门存放自定义注解的

#### 1.7.2 自定义切面类 统一拦截加入了AutoFill注解的方法，通过反射为公共字段赋值

```
package com.sky.aspect;

import com.sky.annotation.AutoFill;
import com.sky.constant.AutoFillConstant;
import com.sky.context.BaseContext;
import com.sky.enumeration.OperationType;
import lombok.extern.slf4j.Slf4j;
import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Before;
import org.aspectj.lang.annotation.Pointcut;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.stereotype.Component;

import java.lang.reflect.Method;
import java.time.LocalDateTime;

/**
 * 自定义切面类， 实现公共字段填充处理逻辑
 */
@Aspect
@Component
@Slf4j
public class AutoFillAspect {
    /**
     * 切入点
     */
    // "execution(* com.sky.mapper.*.*(..))  第一个 '*' 为返回值所有，
    // 'mapper.*.*' 这个意思是mapper中所有的类（mapper后的第一个 ‘*’），所有的方法（第二个）
    // @annotation(com.sky.annotation.AutoFill)"  这个是要拦截的那些注解
    @Pointcut("execution(* com.sky.mapper.*.*(..)) && @annotation(com.sky.annotation.AutoFill)")
    public void autoFillPointCut(){}

    /**
     * 前置通知 @Before("切入点函数")
     */
    @Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint) {
        log.info("开始进行公共字段自动填充...");

        // 获取当前被拦截的方法上的数据库类型
        MethodSignature signature = (MethodSignature)joinPoint.getSignature(); // 方法签名对象
        AutoFill autoFill = signature.getMethod().getAnnotation(AutoFill.class); // 获得方法上的注解对象
        OperationType operationType = autoFill.value(); // 获得数据库的操作类型 EmployeeMapper中的autofill中的value

        // 获取当前被拦截的方法的参数--实体对象
        Object[] args = joinPoint.getArgs(); // 获得所有的实体类方法 EmployeeMapper中的方法
        if (args == null || args.length == 0) { // 判断是否为空
            return;
        }
        Object entity = args[0];

        // 准备赋值的数据
        LocalDateTime now = LocalDateTime.now();
        Long currentId = BaseContext.getCurrentId();

        // 根据当前不同的操作类型，为对应的属性通过反射赋值
        if (operationType == OperationType.INSERT) {
            // 为4个公共字段赋值
            try {
                Method setCreateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class);
                Method setCreateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER, Long.class);
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                // 通过反射来为对象属性赋值
                setCreateTime.invoke(entity, now);
                setCreateUser.invoke(entity, currentId);
                setUpdateTime.invoke(entity, now);
                setUpdateUser.invoke(entity, currentId);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        } else if (operationType == OperationType.UPDATE) {
            // 为2个公共字段赋值
            try {
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                // 通过反射来为对象属性赋值
                setUpdateTime.invoke(entity, now);
                setUpdateUser.invoke(entity, currentId);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

    }
}

```



#### 1.7.3 在Mapper的方法上加入AutoFill注解

```
    @AutoFill(value = OperationType.INSERT)
    void insert(Category category);
```

> 直接使用即可

### 1.8 使用阿里云Oss存储图片 p37

#### 1.8.1进行yml中配置相应的文件

- sky-server/src/main/resources/application.yml

```
spring:
  profiles:
    active: dev
  main:
    allow-circular-references: true
sky:
  alioss:
    endpoint: ${sky.alioss.endpoint}
    assess-key-id: ${sky.alioss.assess-key-id}
    access-key-secret: ${sky.alioss.access-key-secret}
    bucket-name: ${sky.alioss.bucket-name}
```

- sky-server/src/main/resources/application-dev.yml

```
sky:
  alioss:
    endpoint: oss-cn-beijing.aliyuncs.com
    access-key-id: LTAI5tPBUNpiqnX1aE3oMxrz
    access-key-secret: RjBtzgZGxggKthpFmauys1qU3u1Fts
    bucket-name: congmu-sky-takeaway
```

> 这个是application.yml从application-dev.yml中引入的，dev是生产环境的yml，到时候可以快速修改

#### 1.8.2 编写实体类，获取yml文件中的数据

- com.sky.properties.AliOssProperties

```
package com.sky.properties;

import lombok.Data;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

@Component
@ConfigurationProperties(prefix = "sky.alioss")
@Data
public class AliOssProperties {


    private String endpoint;
    private String accessKeyId;
    private String accessKeySecret;
    private String bucketName;

}
```

> 这个直接@ConfigurationProperties(prefix = "sky.alioss")使用这个来进行一键绑定了，并且这种类都在properties包下

#### 1.8.3 编写工具类，将文件上传工具类

```
package com.sky.utils;

import com.aliyun.oss.ClientException;
import com.aliyun.oss.OSS;
import com.aliyun.oss.OSSClientBuilder;
import com.aliyun.oss.OSSException;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.extern.slf4j.Slf4j;
import java.io.ByteArrayInputStream;

@Data
@AllArgsConstructor
@Slf4j
public class AliOssUtil {

    private String endpoint;
    private String accessKeyId;
    private String accessKeySecret;
    private String bucketName;

    /**
     * 文件上传
     *
     * @param bytes
     * @param objectName
     * @return
     */
    public String upload(byte[] bytes, String objectName) {

        // 创建OSSClient实例。
        OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret);

        try {
            // 创建PutObject请求。
            ossClient.putObject(bucketName, objectName, new ByteArrayInputStream(bytes));
        } catch (OSSException oe) {
            System.out.println("Caught an OSSException, which means your request made it to OSS, "
                    + "but was rejected with an error response for some reason.");
            System.out.println("Error Message:" + oe.getErrorMessage());
            System.out.println("Error Code:" + oe.getErrorCode());
            System.out.println("Request ID:" + oe.getRequestId());
            System.out.println("Host ID:" + oe.getHostId());
        } catch (ClientException ce) {
            System.out.println("Caught an ClientException, which means the client encountered "
                    + "a serious internal problem while trying to communicate with OSS, "
                    + "such as not being able to access the network.");
            System.out.println("Error Message:" + ce.getMessage());
        } finally {
            if (ossClient != null) {
                ossClient.shutdown();
            }
        }

        //文件访问路径规则 https://BucketName.Endpoint/ObjectName
        StringBuilder stringBuilder = new StringBuilder("https://");
        stringBuilder
                .append(bucketName)
                .append(".")
                .append(endpoint)
                .append("/")
                .append(objectName);

        log.info("文件上传到:{}", stringBuilder.toString());

        return stringBuilder.toString();
    }
}

```

> 该是阿里云官方的代码，做了些许修改，例如适配1.8.1和2

#### 1.8.4 编写配置类， 直接在项目启动的时候将1.8.2的类的数据赋值给1.8.3工具类

```
package com.sky.config;

import com.sky.properties.AliOssProperties;
import com.sky.utils.AliOssUtil;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * 配置类 用于创建AliOssUtil对象
 */
@Configuration
@Slf4j
public class OssConfiguration {

    @Bean
    // 保证spring容器中只有一个对象
    @ConditionalOnMissingBean
    public AliOssUtil aliOssUtil(AliOssProperties aliOssProperties) {
        log.info("开始创建阿里云文件上传工具类对象：{}", aliOssProperties);
        return new AliOssUtil(aliOssProperties.getEndpoint(),
                aliOssProperties.getAccessKeyId(),
                aliOssProperties.getAccessKeySecret(),
                aliOssProperties.getBucketName());
    }
}
```

#### 1.8.5 controller 层使用

```
package com.sky.controller.admin;

import com.sky.constant.MessageConstant;
import com.sky.result.Result;
import com.sky.utils.AliOssUtil;
import io.swagger.annotations.Api;
import io.swagger.annotations.ApiOperation;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.util.UUID;

@Slf4j
@RestController
@RequestMapping("/admin/common")
@Api(tags = "通用接口")
public class CommonController {
    @Autowired
    private AliOssUtil aliOssUtil;
    /**
     * 文件上传
     * @param file
     * @return
     */
    @PostMapping("/upload")
    @ApiOperation("文件上传")
    public Result<String> upload(MultipartFile file) {
        log.info("文件上传:{} ", file);

        try {
            // 原始文件名
            String originalFilename = file.getOriginalFilename();
            // 截取原始文件名的后缀
            String extension = originalFilename.substring(originalFilename.lastIndexOf("."));
            // 构建新文件名称
            String objectName = UUID.randomUUID().toString() + extension;
            // 文件的请求路径
            String filePath = aliOssUtil.upload(file.getBytes(), objectName);
            return Result.success(filePath);
        } catch (IOException e) {
            log.error("文件上传失败： {}", e);
            // throw new RuntimeException(e);
        }
        return Result.error(MessageConstant.UPLOAD_FAILED);
    }

}
```

> 中间使用uuid进行重命名即可





### 1.9 Transactional注解使用 && 插入后获取id p38-39

> 当涉及到多张表的时候保证方法是一个原子性的， 例如本例中，新增菜品和口味，全成功或者全失败

记得在启动类上开启注解方式的事务管理

```
@SpringBootApplication
@EnableTransactionManagement //开启注解方式的事务管理
@Slf4j
public class SkyApplication {
    public static void main(String[] args) {
        SpringApplication.run(SkyApplication.class, args);
        log.info("server started");
    }
}
```

- xml中

```\
    <insert id="insert" useGeneratedKeys="true" keyProperty="id">
```

> 这个useGeneratedKeys是获取插入后生成的id，keyProperty是将获取后的id注入实体类

- ServiceImpl中

```
        Dish dish = new Dish();
        BeanUtils.copyProperties(dishDTO, dish);
        // 像菜品表中插入1条数据
        dishMapper.insert(dish);

        // 获取insert语句生成的id
        Long dishId = dish.getId();

        // 向口味表中插入n条数据
        List<DishFlavor> flavors = dishDTO.getFlavors();
        if (flavors != null && flavors.size() > 0) {
            // 将获取的dishId插入到口味表中
            flavors.forEach(dishFlavor -> {
                dishFlavor.setDishId(dishId);
            });
            DishFlavorMapper.insertBatch(flavors);
        }
```

> 获取实体类id就可以使用了， 可以将dishId插入到口味表中





### 1.10 Spring Cache p91

#### 1.10.1 介绍

Spring Cache 是一个框架，实现了基于注解的缓存功能，只需要简单地加一个注解，就能实现缓存功能。

Spring Cache 提供了一层抽象，底层可以切换不同的缓存实现，例如：

- EHCache
- Caffeine
- Redis(常用)

**起步依赖：**

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-cache</artifactId>  		            		       	 <version>2.7.3</version> 
</dependency>
```



**常用注解：**

在SpringCache中提供了很多缓存操作的注解，常见的是以下的几个：

| **注解**       | **说明**                                                     |
| -------------- | ------------------------------------------------------------ |
| @EnableCaching | 开启缓存注解功能，通常加在启动类上                           |
| @Cacheable     | 在方法执行前先查询缓存中是否有数据，如果有数据，则直接返回缓存数据；如果没有缓存数据，调用方法并将方法返回值放到缓存中 |
| @CachePut      | 将方法的返回值放到缓存中                                     |
| @CacheEvict    | 将一条或多条数据从缓存中删除                                 |

在spring boot项目中，使用缓存技术只需在项目中导入相关缓存技术的依赖包，并在启动类上使用@EnableCaching开启缓存支持即可。

例如，使用Redis作为缓存技术，只需要导入Spring data Redis的maven坐标即可。

#### 1.10.2 使用

> 这个跟redis联合使用， 只不过将redis改为注解的方式来写了

[3.4 通过redis来将数据存到内存中 p87](#3.4 通过redis来将数据存到内存中 p87)

- @Cacheable例子（第九行）

	/**
	 * 条件查询
	 *
	 * @param categoryId
	 * @return
	 */
	@GetMapping("/list")
	@ApiOperation("根据分类id查询套餐")
	@Cacheable(cacheNames = "setmealCache",key = "#categoryId") //key: setmealCache::100
	public Result<List<Setmeal>> list(Long categoryId) {
	    Setmeal setmeal = new Setmeal();
	    setmeal.setCategoryId(categoryId);
	    setmeal.setStatus(StatusConstant.ENABLE);
	
	    List<Setmeal> list = setmealService.list(setmeal);
	    return Result.success(list);
	}

- @CacheEvict

```
    @CacheEvict(cacheNames = "setmealCache",key = "#setmealDTO.categoryId")//key: setmealCache::100
    public Result save(@RequestBody SetmealDTO setmealDTO) {
        setmealService.saveWithDish(setmealDTO);
        return Result.success();
    }
    @CacheEvict(cacheNames = "setmealCache",allEntries = true) // allEntries = true这个是删除该setmealCache下的全部
```



### 1.11 微信支付









## 2 nginx

### 2.1 nginx反向代理

> **nginx 反向代理**，就是将前端发送的动态请求由 nginx 转发到后端服务器

- 前端请求地址：http://localhost/api/employee/login

  后端接口地址：http://localhost:8080/admin/employee/login

  两者不一，可以使用nginx反向代理进行转发

#### 2.1.1 nginx 反向代理的配置方式：

```nginx
server{
    listen 80;
    server_name localhost;
    
    location /api/{
        proxy_pass http://localhost:8080/admin/; #反向代理
    }
}
```

**proxy_pass：**该指令是用来设置代理服务器的地址，可以是主机名称，IP地址加端口号等形式。

如上代码的含义是：监听80端口号， 然后当我们访问 http://localhost:80/api/../..这样的接口的时候，它会通过 location /api/ {} 这样的反向代理到 http://localhost:8080/admin/上来。





## 3 Redis p50

### 3.1 启动Redis

```
redis-server.exe redis.windows.conf
```

### 3.2 Redis常用命令 p52

#### 3.2.1 字符串

> 字符串(string): 普通字符串，Redis中最简单的数据类型

Redis 中字符串类型常用命令：

```
SET key value 			        设置指定key的值
GET key                         获取指定key的值
SETEX key seconds value         设置指定key的值，并将 key 的过期时间设为 seconds 秒
SETNX key value                 只有在 key不存在时设置 key 的值
```



#### 3.2.2 哈希

> 哈希(hash):也叫散列，类似于Java中的HashMap结构

Redis hash 是一个string类型的 field 和 value 的映射表，hash特别适合用于存储对象，常用命令：

```
HSET key field value             将哈希表 key 中的字段 field 的值设为 value
HGET key field                   获取存储在哈希表中指定字段的值
HDEL key field                   删除存储在哈希表中的指定字段
HKEYS key                        获取哈希表中所有字段
HVALS key                        获取哈希表中所有值
```





#### 3.2.3 列表

> 列表(list): 按照插入顺序排序，可以有重复元素，类似于Java中的LinkedList

Redis 列表是简单的字符串列表，按照插入顺序排序，常用命令：

```
LPUSH key value1 [value2]        将一个或多个值插入到列表头部
LRANGE key start stop            获取列表指定范围内的元素
RPOP key                         移除并获取列表最后一个元素
LLEN key                         获取列表长度
BRPOP key1 [key2 ] timeout       移出并获取列表的最后一个元素,如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
```





#### 3.2.4 集合

> 集合(set):无序集合，没有重复元素，类似于Java中的HashSet

Redis set 是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据，常用命令：

```
SADD key member1 [member2]            向集合添加一个或多个成员
SMEMBERS key                          返回集合中的所有成员
SCARD key                             获取集合的成员数
SINTER key1 [key2]                    返回给定所有集合的交集
SUNION key1 [key2]                    返回所有给定集合的并集
SREM key member1 [member2]            移除集合中一个或多个成员
```





#### 3.2.5 有序集合

> 有序集合(sorted set /zset): 集合中每个元素关联一个分数(score)，根据分数升序排序，没有重复元素

Redis有序集合是string类型元素的集合，且不允许有重复成员。每个元素都会关联一个double类型的分数。常用命令：

```
ZADD key score1 member1 [score2 member2]     向有序集合添加一个或多个成员
ZRANGE key start stop [WITHSCORES]           通过索引区间返回有序集合中指定区间内的成员
ZINCRBY key increment member                 有序集合中对指定成员的分数加上增量 increment
ZREM key member [member ...]                 移除有序集合中的一个或多个成员
```



#### 3.2.6 通用命令

> Redis的通用命令是不分数据类型的，都可以使用的命令：

```
KEYS pattern 	查找所有符合给定模式( pattern)的 key 
EXISTS key 		检查给定 key 是否存在
TYPE key 		返回 key 所储存的值的类型
DEL key 		该命令用于在 key 存在是删除 key
```



### 3.3 SpringBoot Data Redis使用 p58

#### 3.3.1 导入Spring Data Redis 的maven坐标

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```



#### 3.3.2 配置Redis数据源

在application-dev.yml中添加

```yaml
sky:
  redis:
    host: localhost
    port: 6379
    password: 123456
    database: 10
```

**解释说明：**

database:指定使用Redis的哪个数据库，Redis服务启动后默认有16个数据库，编号分别是从0到15。

可以通过修改Redis配置文件来指定数据库的数量。

在application.yml中添加读取application-dev.yml中的相关Redis配置

```yaml
spring:
  profiles:
    active: dev
  redis:
    host: ${sky.redis.host}
    port: ${sky.redis.port}
    password: ${sky.redis.password}
    database: ${sky.redis.database}
```



#### 3.3.3 编写配置类，创建RedisTemplate对象

```
package com.sky.config;

import lombok.extern.slf4j.Slf4j;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.StringRedisSerializer;

@Configuration
@Slf4j
public class RedisConfiguration {

    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) {
        RedisTemplate redisTemplate = new RedisTemplate();
        // 设置redis的连接工厂对象
        redisTemplate.setConnectionFactory(redisConnectionFactory);
        // 设置redis key的序列化
        redisTemplate.setKeySerializer(new StringRedisSerializer());
        return redisTemplate;
    }
}
 
```

> 当前配置类不是必须的，因为 Spring Boot 框架会自动装配 RedisTemplate 对象，但是默认的key序列化器为
>
> JdkSerializationRedisSerializer，导致我们存到Redis中后的数据和原始数据有差别，故设置为StringRedisSerializer序列化器。
>



#### 3.3.4 java通过RedisTemplate对象操作Redis

- 创建测试类

```
package com.sky.test;

import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.data.redis.connection.DataType;
import org.springframework.data.redis.core.*;

import java.util.List;
import java.util.Set;
import java.util.concurrent.TimeUnit;

@SpringBootTest
public class SpringDataRedisTest {

    @Autowired
    private RedisTemplate redisTemplate;

    @Test
    public void testRedisTemplate() {
        System.out.println(redisTemplate);
        //string数据操作
        ValueOperations valueOperations = redisTemplate.opsForValue();
        //hash类型的数据操作
        HashOperations hashOperations = redisTemplate.opsForHash();
        //list类型的数据操作
        ListOperations listOperations = redisTemplate.opsForList();
        //set类型数据操作
        SetOperations setOperations = redisTemplate.opsForSet();
        //zset类型数据操作
        ZSetOperations zSetOperations = redisTemplate.opsForZSet();
    }

    /**
     * 操作字符串
     */
    @Test
    public void testString() {
        // set get setex setnx
        redisTemplate.opsForValue().set("city", "北京");
        String city = (String) redisTemplate.opsForValue().get("city");
        System.out.println("String中的city：" + city);

        redisTemplate.opsForValue().set("code", "1234", 3, TimeUnit.MINUTES);
        redisTemplate.opsForValue().setIfAbsent("lock", "1");
        redisTemplate.opsForValue().setIfAbsent("lock", "2");
    }

    /**
     * 操作哈希类型的数据
     */
    @Test
    public void testHash() {
        //hset hget hdel hkeys hvals
        HashOperations hashOperations = redisTemplate.opsForHash();

        hashOperations.put("100", "name", "tom");
        hashOperations.put("100", "age", "20");

        String name = (String)hashOperations.get("100", "name");
        System.out.println("hash中的name：" + name);

        Set keys = hashOperations.keys("100");
        System.out.println("hash中获取所有的keys： " + keys);

        List values = hashOperations.values("100");
        System.out.println("hash中获取所有的value：" + values);

    }

    /**
     * 操作列表类型的数据
     */
    @Test
    public void testList(){
        //lpush lrange rpop llen
        ListOperations listOperations = redisTemplate.opsForList();

        listOperations.leftPushAll("mylist","a","b","c");
        listOperations.leftPush("mylist","d");

        List mylist = listOperations.range("mylist", 0, -1);
        System.out.println(mylist);

        listOperations.rightPop("mylist");

        Long size = listOperations.size("mylist");
        System.out.println(size);
    }

    /**
     * 操作集合类型的数据
     */
    @Test
    public void testSet(){
        //sadd smembers scard sinter sunion srem
        SetOperations setOperations = redisTemplate.opsForSet();

        setOperations.add("set1","a","b","c","d");
        setOperations.add("set2","a","b","x","y");

        Set members = setOperations.members("set1");
        System.out.println(members);

        Long size = setOperations.size("set1");
        System.out.println(size);

        Set intersect = setOperations.intersect("set1", "set2");
        System.out.println(intersect);

        Set union = setOperations.union("set1", "set2");
        System.out.println(union);

        setOperations.remove("set1","a","b");
    }

    /**
     * 操作有序集合类型的数据
     */
    @Test
    public void testZset(){
        //zadd zrange zincrby zrem
        ZSetOperations zSetOperations = redisTemplate.opsForZSet();

        zSetOperations.add("zset1","a",10);
        zSetOperations.add("zset1","b",12);
        zSetOperations.add("zset1","c",9);

        Set zset1 = zSetOperations.range("zset1", 0, -1);
        System.out.println(zset1);

        zSetOperations.incrementScore("zset1","c",10);

        zSetOperations.remove("zset1","a","b");
    }

    /**
     * 通用命令操作
     */
    @Test
    public void testCommon(){
        //keys exists type del
        Set keys = redisTemplate.keys("*");
        System.out.println(keys);

        Boolean name = redisTemplate.hasKey("name");
        Boolean set1 = redisTemplate.hasKey("set1");

        for (Object key : keys) {
            DataType type = redisTemplate.type(key);
            System.out.println(type.name());
        }

        redisTemplate.delete("mylist");
    }

}

```





### 3.4 通过redis来将数据存到内存中 p87

> 如果使用注解转到

[1.10.2 使用](#1.10.2 使用)

#### 3.4.1设置redis

> 实际就是查的时候进行判断
>
> 1. // 查询redis中是否存在菜品数据
> 2. // 如果存在， 直接返回， 无需查询数据库
> 3.  // 如果不存在， 查询数据库，并将此查询放在redis中
>
> 就这个三步，如果是普通的话只有查询数据库

```
    /**
     * 根据分类id查询菜品
     *
     * @param categoryId
     * @return
     */
    @GetMapping("/list")
    @ApiOperation("根据分类id查询菜品")
    public Result<List<DishVO>> list(Long categoryId) {

        // 查询redis中是否存在菜品数据
        String key = "dish_" + categoryId;
        List<DishVO> redisList = (List<DishVO>) redisTemplate.opsForValue().get(key);
        if (redisList != null && redisList.size() > 0) {
            // 如果存在， 直接返回， 无需查询数据库
            return Result.success(redisList);
        }

        Dish dish = new Dish();
        dish.setCategoryId(categoryId);
        dish.setStatus(StatusConstant.ENABLE);//查询起售中的菜品

        // 如果不存在， 查询数据库，并将此查询放在redis中
        List<DishVO> list = dishService.listWithFlavor(dish);
        redisTemplate.opsForValue().set(key, list);

        return Result.success(list);
    }

}
```



#### 3.4.2 清除redis缓存数据



> 如果是修改了数据库中的内容，例如菜品价格，这时候需要清除redis中的数据，防止与数据库中的不一致， 以下是例子

为了保证**数据库**和**Redis**中的数据保持一致，修改**管理端接口 DishController** 的相关方法，加入清理缓存逻辑。

需要改造的方法：

- 新增菜品
- 修改菜品
- 批量删除菜品
- 起售、停售菜品

**抽取清理缓存的方法：**

在管理端DishController中添加

```java
	@Autowired
    private RedisTemplate redisTemplate;
	/**
     * 清理缓存数据
     * @param pattern
     */
    private void cleanCache(String pattern){
        Set keys = redisTemplate.keys(pattern);
        redisTemplate.delete(keys);
    }
```

**调用清理缓存的方法，保证数据一致性：**

**1). 新增菜品优化**

```java
	/**
     * 新增菜品
     *
     * @param dishDTO
     * @return
     */
    @PostMapping
    @ApiOperation("新增菜品")
    public Result save(@RequestBody DishDTO dishDTO) {
        log.info("新增菜品：{}", dishDTO);
        dishService.saveWithFlavor(dishDTO);

        //清理缓存数据
        String key = "dish_" + dishDTO.getCategoryId();
        cleanCache(key);
        return Result.success();
    }
```

**2). 菜品批量删除优化**

```java
	/**
     * 菜品批量删除
     *
     * @param ids
     * @return
     */
    @DeleteMapping
    @ApiOperation("菜品批量删除")
    public Result delete(@RequestParam List<Long> ids) {
        log.info("菜品批量删除：{}", ids);
        dishService.deleteBatch(ids);

        //将所有的菜品缓存数据清理掉，所有以dish_开头的key
        cleanCache("dish_*");

        return Result.success();
    }
```

**3). 修改菜品优化**

```java
	/**
     * 修改菜品
     *
     * @param dishDTO
     * @return
     */
    @PutMapping
    @ApiOperation("修改菜品")
    public Result update(@RequestBody DishDTO dishDTO) {
        log.info("修改菜品：{}", dishDTO);
        dishService.updateWithFlavor(dishDTO);

        //将所有的菜品缓存数据清理掉，所有以dish_开头的key
        cleanCache("dish_*");

        return Result.success();
    }
```

**4). 菜品起售停售优化**

```java
	/**
     * 菜品起售停售
     *
     * @param status
     * @param id
     * @return
     */
    @PostMapping("/status/{status}")
    @ApiOperation("菜品起售停售")
    public Result<String> startOrStop(@PathVariable Integer status, Long id) {
        dishService.startOrStop(status, id);

        //将所有的菜品缓存数据清理掉，所有以dish_开头的key
        cleanCache("dish_*");

        return Result.success();
    }
```



